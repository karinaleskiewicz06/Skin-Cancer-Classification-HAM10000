{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karinaleskiewicz06/Skin-Cancer-Classification-HAM10000/blob/main/ansatz_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLzI6vhj-pd"
      },
      "source": [
        "\n",
        "\n",
        "##Quantum Classifier - ansatz comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install qiskit qiskit_machine_learning\n",
        "%pip install ucimlrepo\n",
        "%pip install torch\n",
        "%pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qy5f6-Mjv3in",
        "outputId": "a0a787bb-ab86-4f92-d6ad-60c90a1bfe9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.3.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Downloading qiskit-2.3.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_machine_learning-0.9.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit, qiskit_machine_learning\n",
            "Successfully installed qiskit-2.3.0 qiskit_machine_learning-0.9.0 rustworkx-0.17.1 stevedore-5.6.0\n",
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LKSJGRyG0ouM"
      },
      "outputs": [],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "import sys          # Standard library module for system-specific parameters and functions\n",
        "import subprocess   # Standard library module for spawning new processes\n",
        "from sklearn.preprocessing import MinMaxScaler # Importuje MinMaxScaler do skalowania danych\n",
        "from sklearn.model_selection import train_test_split # Importuje train_test_split do podziaÅ‚u danych\n",
        "from ucimlrepo import fetch_ucirepo     # Importuje fetch_ucirepo do pobierania zestawÃ³w danych z UCI ML Repository\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "enUz4SJl6Fnh"
      },
      "outputs": [],
      "source": [
        "def ensure_package(pkg_name, import_name=None):\n",
        "    import_name = import_name or pkg_name\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
        "\n",
        "# Ensure all requirements are met\n",
        "ensure_package('numpy')\n",
        "ensure_package('scikit-learn', 'sklearn')\n",
        "ensure_package('ucimlrepo')\n",
        "ensure_package('qiskit')\n",
        "\n",
        "def prepare_data():\n",
        "    \"\"\"\n",
        "    Fetches the banknote authentication dataset and returns scaled train/test splits.\n",
        "    Features are scaled to [0, pi] specifically for Angle Encoding.\n",
        "    \"\"\"\n",
        "    banknote_authentication = fetch_ucirepo(id=267)\n",
        "    X = banknote_authentication.data.features.to_numpy()\n",
        "    y = banknote_authentication.data.targets.to_numpy().ravel()\n",
        "\n",
        "    variance = X[:, 0].reshape(-1, 1)\n",
        "    skewness = X[:, 1].reshape(-1, 1)\n",
        "\n",
        "    interaction = skewness * variance\n",
        "    X_expanded = np.hstack((X, interaction))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_expanded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "\n",
        "# Global availability of data\n",
        "X_tr, X_te, y_tr, y_te = prepare_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸ”¬ Ansatz 1: Global Ring Entangler (Simulation-Optimized)"
      ],
      "metadata": {
        "id": "XVh14trAwFyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**Overview**\n",
        "\n",
        "This ansatz is designed to maximize expressibility and entanglement capability by leveraging a global connectivity pattern. It follows a \"Circuit-centric\" design philosophy, prioritizing high-dimensional state representation to achieve superior classification performance in ideal environments.\n",
        "\n",
        "##**Technical Architecture**\n",
        "\n",
        " * **Layered Structure:** The circuit employs a dual-layer strategy consisting of\n",
        "independent rotation sub-layers ($RY$, $RX$) and sophisticated entanglement blocks.\n",
        " * **Ring Topology:** Entanglement is implemented via a circular chain where each qubit $i$ is coupled with qubit $(i+1) \\pmod n$. This ensures that information from any qubit can reach any other qubit in the shortest possible path.\n",
        " * **Parametric Controlled Rotations:** Unlike standard CNOT-based circuits, this model utilizes CRX and CRY gates. These allow the model to learn not just whether to entangle, but the intensity of the entanglement, leading to high-precision decision boundaries.\n",
        " * **Reverse-Flow Correlation:** The second sub-layer reverses the entanglement direction ($i \\to i-1$), facilitating a rapid diffusion of features across the entire register.\n",
        " * **Performance & Benchmarks:**\n",
        "    In noise-free simulations, this architecture demonstrates exceptional learning capabilities:\n",
        "      * **Accuracy:** consistently achieves **>90%** on binary classification tasks.\n",
        "      * **Flexibility:** High parameter density allows for complex non-linear mapping of input data.\n",
        "  \n",
        "##**Scientific Reference**\n",
        "\n",
        "  The implementation of this ansatz is based on the architectural principles discussed in: [Quantum Machine Learning in Liquid â€“ HavlÃ­Äek et al. (2019) arXiv:1905.10876](https://https://arxiv.org/abs/1905.10876)\n",
        "  \n",
        "##**The \"Hardware Gap\" (Motivation for Ansatz 2)**\n",
        "While mathematically superior, Ansatz 1 poses significant challenges for physical quantum processors like the Odra system:\n",
        "* **Connectivity Constraints:** Real hardware rarely supports a physical \"Ring.\" Connecting the first and last qubits requires multiple SWAP gates, which significantly increase circuit depth and decoherence.\n",
        "* **Gate Decomposition:** $CRX$ and $CRY$ are not native gates. On hardware, they are decomposed into multiple CNOTs and single-qubit rotations, multiplying the error rate for every single operation."
      ],
      "metadata": {
        "id": "BXTxoldF8967"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pz4kqrFfANdX"
      },
      "outputs": [],
      "source": [
        "def ansatz(n_qubits, depth):\n",
        "    \"\"\"\n",
        "    The code below constructs the ansatz. It is built using the Qiskit library\n",
        "    and utilizes its built-in tools, such as ParameterVector, to easily iterate\n",
        "    over rotation gate parameters.\n",
        "\n",
        "    The implementation assumes an even number of layers (depth). Each layer consists\n",
        "    of a sub-layer of independent gates and a sub-layer of entanglement.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a vector of learnable parameters.\n",
        "    # Total parameters = 2 * num_qubits * depth (2 * n_qubits per full loop iteration).\n",
        "    theta = ParameterVector('Î¸', 2 * n_qubits * depth)\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    param_idx = 0\n",
        "\n",
        "    # The loop iterates (depth // 2) times.\n",
        "    for j in range(depth // 2):\n",
        "\n",
        "        # -------- Layer 1 --------\n",
        "\n",
        "        # Sub-layer: Independent RY rotations\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(theta[param_idx], i)\n",
        "            param_idx += 1\n",
        "\n",
        "        # Sub-layer: Entanglement (CRX) - Ring Topology\n",
        "        # Connects i -> i+1 (wrapping around to 0 at the end)\n",
        "        for i in range(n_qubits):\n",
        "            control = i\n",
        "            target = (i + 1) % n_qubits\n",
        "            qc.crx(theta[param_idx], control, target)\n",
        "            param_idx += 1\n",
        "\n",
        "\n",
        "        # -------- Layer 2 --------\n",
        "\n",
        "        # Sub-layer: Independent RX rotations\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(theta[param_idx], i)\n",
        "            param_idx += 1\n",
        "\n",
        "        # Sub-layer: Entanglement (CRY) - Reverse Ring Topology\n",
        "        # Connects i -> i-1 (wrapping around to N-1)\n",
        "        for i in range(n_qubits):\n",
        "            control = i\n",
        "            target = (i - 1) % n_qubits\n",
        "            qc.cry(theta[param_idx], control, target)\n",
        "            param_idx += 1\n",
        "\n",
        "    return qc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ma=ansatz(5,2)\n",
        "ma.draw(style=\"mpl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "gf6trUuHxKpZ",
        "outputId": "bd9b7449-faa9-4094-a018-28bbdfd87e66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[9]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rx(Î¸[5]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[6]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[12]) â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[8]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[10]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[16]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[17]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[13]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[14]) â”œâ”¤ Ry(Î¸[15]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                  \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "Â«q_3: â”¤ Ry(Î¸[19]) â”œ\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€\n",
              "Â«                  "
            ],
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[9]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rx(Î¸[5]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[6]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[12]) â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[8]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[10]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[16]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[17]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[13]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[14]) â”œâ”¤ Ry(Î¸[15]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                  \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "Â«q_3: â”¤ Ry(Î¸[19]) â”œ\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€\n",
              "Â«                  </pre>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z_JEkN9KJ-Fh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    The code below constructs the class HybridModel. It is built using the Qiskit and Pytorch library and\n",
        "    and utilizes its built-in tools, to create a model connecting classical and quantum computing.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, ansatz_circuit, num_qubits):\n",
        "        super().__init__()\n",
        "        self.feature_map = self.angle_encoding(num_qubits)\n",
        "\n",
        "        # Connecting the quantum circuit. Connecting our feature map (data) and ansatz\n",
        "        self.qc = QuantumCircuit(num_qubits)\n",
        "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
        "        self.qc.compose(ansatz_circuit, inplace=True)\n",
        "\n",
        "        # Firstly, we inicialize parameters. Our quantum model cannot tell whether the number came from ansatz or feature.\n",
        "        # That is why here we sort them into two lists. If the number came from feature_map, then it will be a feature and the other way around.\n",
        "        input_params = list(self.feature_map.parameters)\n",
        "        weight_params = list(ansatz_circuit.parameters)\n",
        "\n",
        "        '''\n",
        "        Measure the Z-operator (spin) on the very first qubit (q_0) and ignore all the other qubits.\n",
        "        Qiskit reads the string in a reversed order, that is why the Z gate is on the end.\n",
        "        SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)]) converts string into a mathematical matrix that Qiskit can use for calculations\n",
        "        Coefficient = 1 is a weight we multiply our result by. In QML it is mostly set to 1\n",
        "        '''\n",
        "\n",
        "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
        "\n",
        "        # Estimator takes ansatz, observables and parameters (data and weights), returns the Expectation value.\n",
        "        # !!!! CHANGE WHEN USING ON QUANTUM COMPUTER\n",
        "        # Needed when running quantum simulations, it should be changed when implementing on real quantum computer\n",
        "        estimator = StatevectorEstimator()\n",
        "\n",
        "        # Compute the gradients of the sampling probability by the Parameter Shift Rule.\n",
        "        gradient = ParamShiftEstimatorGradient(estimator)\n",
        "\n",
        "\n",
        "        '''\n",
        "        The EstimatorQNN\n",
        "        This class from Qiskit Machine Learning is used to instantiate the quantum neural network.\n",
        "        It leverages the Qiskit Primitives (Estimator) to efficiently calculate expectation values\n",
        "        of the quantum circuit. This allows the model to output continuous, differentiable values (gradients)\n",
        "        required for backpropagation in hybrid quantum-classical training.\n",
        "        '''\n",
        "\n",
        "        self.qnn = EstimatorQNN(\n",
        "            circuit=self.qc,\n",
        "            observables=observable,\n",
        "            input_params=input_params,\n",
        "            weight_params=weight_params,\n",
        "            estimator=estimator,\n",
        "            gradient=gradient\n",
        "        )\n",
        "\n",
        "        '''\n",
        "        TORCH CONNECTOR\n",
        "        This line initializes the TorchConnector, which serves as a bridge between Qiskit and PyTorch. It wraps the Quantum Neural Network (QNN)\n",
        "        to make it function as a standard, differentiable PyTorch module (nn.Module).\n",
        "        This integration allows the quantum parameters to be optimized using standard PyTorch tools like\n",
        "        the Adam optimizer and automatic differentiation.\n",
        "        '''\n",
        "        self.quantum_layer = TorchConnector(self.qnn)\n",
        "\n",
        "        \"\"\"\n",
        "        Creates a Feature Map circuit using Angle Encoding. It maps classical input vectors\n",
        "        to the quantum space by applying Ry(theta) rotations on each qubit,\n",
        "        where the rotation angle theta corresponds to the input feature value.\n",
        "        This effectively encodes the data into the amplitudes of the quantum state\n",
        "        \"\"\"\n",
        "\n",
        "    def angle_encoding(self, num_qubits):\n",
        "        qc_data = QuantumCircuit(num_qubits)\n",
        "        input_params = ParameterVector('x', num_qubits)\n",
        "        for i in range(num_qubits):\n",
        "            qc_data.ry(input_params[i], i)\n",
        "        return qc_data\n",
        "\n",
        "    '''\n",
        "    This function acts as the main execution path. When the model receives data,\n",
        "    the forward function passes it into the quantum layer to be processed.\n",
        "    The quantum layer calculates the result based on the current circuit parameters and returns the prediction.\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        return self.quantum_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv_mmuC3lXfL",
        "outputId": "10ee055a-cb76-4f43-e233-3b334f1e3373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data ready. Number of training samples: 1097\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "print(\"Loading data...\")\n",
        "\n",
        "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
        "\n",
        "y_train = 2 * y_train_raw - 1\n",
        "y_test = 2 * y_test_raw - 1\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "print(f\"Data ready. Number of training samples: {len(X_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vbZY4sy_Dzuh"
      },
      "outputs": [],
      "source": [
        "# --- Preparing the DataLoader ---\n",
        "\n",
        "# Data conversion to tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# Creating a dataset with X_train_tensor and Y_train_tensor\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Creating a DataLoader, which now automatically handles shuffle in the training loop\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "PQpegINFKm1M",
        "outputId": "ee2abd3d-495e-4ba0-b123-090a164dc1c7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training... Epochs: 30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3838536759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/connectors/torch_connector.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# evaluate QNN gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         input_grad, weights_grad = neural_network.backward(\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0minput_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py\u001b[0m in \u001b[0;36m_backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit/primitives/primitive_job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_submitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3572\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3574\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Defining a loss function (note for Axion, it it the same as MichaÅ‚ calculated manually with diff**2)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "\n",
        "# Inicializing the model\n",
        "final_ansatz = ansatz(5, 6)\n",
        "model = HybridModel(final_ansatz, 5)\n",
        "\n",
        "# Initializing the ADAM optimizer\n",
        "# Now that Our HybridModel is written in Pytorch, optimizer can access the paramiters directly\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Starting training... Epochs: {EPOCHS}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batches_count = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()           # Reset gradients\n",
        "        output = model(X_batch)         # Forward\n",
        "        loss = loss_function(output, y_batch) # Loss\n",
        "        loss.backward()                 # Backward\n",
        "        optimizer.step()                # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batches_count += 1\n",
        "\n",
        "    # Evaluation on tensors\n",
        "    with torch.no_grad(): # To test our model we turn off the gradients\n",
        "\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = loss_function(test_outputs, y_test_tensor).item()\n",
        "\n",
        "        # Calculating accuracy:\n",
        "        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\n",
        "        # Then, multiply it by two, so for True = 2.0 False = 0.0\n",
        "        # Substract 1 and the labels are either 1.0 or -1.0\n",
        "        predicted = (test_outputs > 0).float() * 2 - 1\n",
        "        correct = (predicted == y_test_tensor).sum().item()\n",
        "        test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "    avg_loss = epoch_loss / batches_count\n",
        "    train_loss_history.append(avg_loss)\n",
        "    test_loss_history.append(test_loss)\n",
        "    acc_history.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"quantum_symulator_weights.pth\")\n",
        "print(f\"âœ… Wagi zapisane do pliku: quantum_symulator_weights.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKpTxQgZdUGC"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    test_outputs_tensor = model(X_test_tensor)\n",
        "    test_outputs = test_outputs_tensor.numpy()\n",
        "\n",
        "predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
        "\n",
        "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
        "c_matrix_display.plot()\n",
        "\n",
        "epochs = range(1, len(train_loss_history) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
        "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
        "plt.title('Ansatz for Simulator - Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ puÅ›ciÄ‡ to na odrze!!!!!!!!!!!!!!!!!!!!!!!!!"
      ],
      "metadata": {
        "id": "WsFvjlkJ1HBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSATZ 2 - Odra adapted ansatz"
      ],
      "metadata": {
        "id": "Fp9XZyQuwYer"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.12 (Qiskit)",
      "language": "python",
      "name": "qiskit_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}